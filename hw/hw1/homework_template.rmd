---
title: "1st homework assignment"
output: pdf_document
highlight: zenburn
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Task 1 - cleaning data (2 points)

Work with the **customer_behaviour** dataset.

```{r}
load("customer_behaviour.RData")
```

The dataset has 4 columns, each row represents an individual customer: *money_spent* describes the average amount of money customer spends during one visit, *age* is self-explanatory, *web_visits* describes how many times a month customer checks out the shop website, *mail_ads* describes how many advertisement emails the customer gets monthly, *shop_visits* described how many times the customer visits a shop in person a month. Explore each variable and **delete** any rows which have mistakes in them. **Do not fix the mistakes, delete whole rows.**

| number of rows in the cleaned dataset |
|---------------------------------------|
| 481                                   |

## Task 2 - descriptive statistics (3 points)

Work with the cleaned dataset from the previous month **customer_behaviour2**.

```{r}
load("customer_behaviour2.RData")
```

Firstly, create a new variable called `big` where each value equals either 1 (if the person spent more money than 5000 USD), or 0 (if he spent less or equal):

```{r}
data$big = as.numeric(data$money_spent > 5000)
```

Plot two boxplots of the variable *money_spent* into one figure: the first one for observations with the value of *big* equal to 0, the second one for observations with the value of *big* equal to 1. Then create a histogram for the variable *money_spent* together with its kernel density estimation.

```{r, echo = FALSE, out.width="49%"}
#split the plot area and draw both box plots
par(mfrow = c(1, 2))
boxplot(data$money_spent[data$big == 0], main = "Spent <= 5000", xlab = "big = 0", ylab = "money_spent")
boxplot(data$money_spent[data$big == 1], main = "Spent > 5000", xlab = "big = 1", ylab = "money_spent")

#reset area and draw histogram with kernel density
par(mfrow = c(1, 1))
hist(data$money_spent, freq = FALSE)
lines(density(data$money_spent), lwd = 2)
```

Finally, compute following numerical characteristics of the variable *age*:

| mean     | median | $1^{st}$ quartile | $3^{rd}$ quartile | interquartile range | variance |
|----------|--------|-------------------|-------------------|---------------------|----------|
| 54.78882 | 55     | 40                | 68.5              | 28.5                | 344.7146 |

Choose one appropriate measure of location and one appropriate measure of variability for the *money_spent* variable. Input the name of the measure into the following table. Briefly explain why you chose these measures.

| measure of location                              | measure of variability                                                            |
|--------------------------------------------------|-----------------------------------------------------------------------------------|
| median                                           | interquartile range                                                               |
| --------------------                             | ---------------                                                                   |
| It is less influenced by extremes in the dataset | It is less influenced by extremes in the dataset (the dataset seems to be skewed) |

## Task 3 - correlation (2 points)

Compute the correlation matrix of the data from the previous task (excluding the *money_spent* and *big* variables) and the sum of all its diagonal elements. Explain the result of the sum:

```{r, include = F}
# compute the correlation matrix here:
short_data = data[, c("age", "web_visits", "mail_ads", "shop_visits")]
(cor_data = cor(short_data))

# compute the sum of all diagonal elements here:
sum(diag(cor_data))
```

| Sum of diagonal elements | Explanation                                                                                                       |
|--------------------------|-------------------------------------------------------------------------------------------------------------------|
| 4                        | It tells us that the every variable perfectly correlates with itself (and so it tells us the number of variables) |

Compute and **interpret** correlation coeficients between following variables:

| Variables                   | Results    | Interpretation                                                                                                 |
|-----------------------------|------------|----------------------------------------------------------------------------------------------------------------|
| `example`                   | 0          | The correlation is zero, which means...                                                                        |
| `money_spent`, `age`        | -0.6133549 | Moderately high negative correlation. Seems that the older people are, the less money they spend.              |
| `money_spent`, `web_visits` | 0.3725449  | Moderate possitive correlation. Seems that the more people visit the eshop website, the more money they spend. |

Interpretation in the form "correlation coefficient is 0.8 which means the correlation is high" will not be accepted.

## Task 4 - PCA (3 points)

Use PCA on the dataset from the previous task (**customer_behaviour2**, excluding variables *money_spent* and *big*). Use as little components as possible to capture at least 80 % of data variance.

| Number of components used |
|---------------------------|
| 2                         |

State which variable has the most influence on each component.

| \-                      | Component 1 | Component 2 | Component 3 | Component 4 |
|-------------------------|-------------|-------------|-------------|-------------|
| most impactful variable | web_visits  | age         | mail_ads    | shop_visits |

Create a scatter plot of data points using the first two components. Plot the points in different colours depending on the value of the *big* variable. What is your evaluation of the final plot? Can you decipher from the plot which variable(s) seems best at separating *big* shoppers from the customers who spend less?

```{r, include = T}
short_data.pca <- prcomp(short_data, center = T, scale = F)
pca_scores = predict(short_data.pca, short_data)
df = data.frame(PC1 = pca_scores[, 1], PC2 = pca_scores[, 2], big = data$big)
library(ggplot2)
ggplot(df, aes(x = PC1, y = PC2, color = factor(big))) + 
    geom_point()
```

| Scatter plot evaluation                     | Which variable(s) best separates heavy spenders |
|---------------------------------------------|-------------------------------------------------|
| I can see that both groups (light and heavy |                                                 |

spenders) do mix quite a bit in the center.\
There is a difference between them, but they\
do mix. \| Age and web_visited variables. It seems that heavy\
spenders visit the eshop more often and are younger while\
light spenders are older and visit it less. \|
